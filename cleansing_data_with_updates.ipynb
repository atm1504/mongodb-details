{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "cleansing-data-with-updates.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atm1504/mongodb-details/blob/master/cleansing_data_with_updates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfdNd4qg2EsA",
        "colab_type": "text"
      },
      "source": [
        "# Data Cleansing\n",
        "### Things to learn\n",
        "* Import bulk data\n",
        "* Count data by type filter\n",
        "* Modify data (Update)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsj1ADJtm_aM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "39e07804-8b1a-41ef-96cc-92c9330b58d1"
      },
      "source": [
        "# We're going to install this module to help us parse datetimes from the raw dataset\n",
        "!pip3 install dateparser\n",
        "\n",
        "# To install srv link reader\n",
        "!pip3 install pymongo[srv]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dateparser\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/d5/5a2e51bc0058f66b54669735f739d27afc3eb453ab00520623c7ab168e22/dateparser-0.7.6-py2.py3-none-any.whl (362kB)\n",
            "\r\u001b[K     |█                               | 10kB 18.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 6.5MB/s eta 0:00:01\r\u001b[K     |██▊                             | 30kB 7.7MB/s eta 0:00:01\r\u001b[K     |███▋                            | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |████▌                           | 51kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 61kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 71kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 81kB 6.0MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 92kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 102kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 112kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 122kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 133kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 143kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 153kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 163kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 174kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 184kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 194kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 204kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 215kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 225kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 235kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 245kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 256kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 266kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 276kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 286kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 296kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 307kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 317kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 327kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 337kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 348kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 358kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 368kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.02.19 in /usr/local/lib/python3.6/dist-packages (from dateparser) (2019.12.20)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from dateparser) (2.8.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.6/dist-packages (from dateparser) (1.5.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from dateparser) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil->dateparser) (1.12.0)\n",
            "Installing collected packages: dateparser\n",
            "Successfully installed dateparser-0.7.6\n",
            "Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.6/dist-packages (3.10.1)\n",
            "Collecting dnspython<2.0.0,>=1.16.0; extra == \"srv\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/d3/3aa0e7213ef72b8585747aa0e271a9523e713813b9a20177ebe1e939deb0/dnspython-1.16.0-py2.py3-none-any.whl (188kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 8.4MB/s \n",
            "\u001b[?25hInstalling collected packages: dnspython\n",
            "Successfully installed dnspython-1.16.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNox6n1Um_aU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pymongo import MongoClient, InsertOne, UpdateOne\n",
        "import pprint\n",
        "import dateparser\n",
        "from bson.json_util import loads"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjeQEUiVm_aX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replace XXXX with your connection URI from the Atlas UI\n",
        "client = MongoClient(xxxxx)\n",
        "people_raw = client['cleansing']['peoples']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMDzkGQ1zAER",
        "colab_type": "text"
      },
      "source": [
        "Skipping the below step, as I am using google colab and my network spped is slow. I have used a normal python3 script locally to import the data. There are two ways to import data.\n",
        "### Method-1 (In local system)\n",
        "```\n",
        "import bson.json_util\n",
        "from pymongo import InsertOne, MongoClient\n",
        "\n",
        "BATCH_SIZE = 1000  # Batch size for batch insertion\n",
        "\n",
        "cli = MongoClient(Connec tion url\")\n",
        "people_raw = cli.cleansing['peoples']\n",
        "\n",
        "batch_insertions = []\n",
        "with open('people-raw.json') as f:\n",
        "    for line in f:\n",
        "        line_dict = bson.json_util.loads(line)\n",
        "        batch_insertions.append(InsertOne(line_dict))\n",
        "        if len(batch_insertions) == BATCH_SIZE:\n",
        "            people_raw.bulk_write(batch_insertions)\n",
        "            print(f'Finished inserting a batch of {BATCH_SIZE} documents')\n",
        "            batch_insertions = []\n",
        "if batch_insertions:\n",
        "    people_raw.bulk_write(batch_insertions)\n",
        "    print(f'Finished inserting a last batch of {len(batch_insertions)} '\n",
        "          f'documents')\n",
        "\n",
        "print('Finished all the insertions.')\n",
        "```\n",
        "\n",
        "### Method-2 (In google colab)\n",
        "```\n",
        "import json\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "file_name = \"data.json\"\n",
        "io.StringIO[file_name].decode(\"utf-8\")\n",
        "json.loads(uploaded[file_name].decode(\"utf-8\"))\n",
        "```\n",
        "\n",
        "Now parse the data in the following way:\n",
        "```\n",
        "uploaded[file_name].decode(\"utf-8\") as dataset: \n",
        "    for line in dataset: \n",
        "        inserts.append(InsertOne(loads(line)))\n",
        "        \n",
        "        count += 1\n",
        "                       \n",
        "        if count == batch_size:\n",
        "            people_raw.bulk_write(inserts)\n",
        "            inserts = []\n",
        "            count = 0\n",
        "if inserts:         \n",
        "    people_raw.bulk_write(inserts)\n",
        "    count = 0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wp8vESdN1xeD",
        "colab_type": "text"
      },
      "source": [
        "### Method -3 (Prefered way)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BaIY_6n1uZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1000\n",
        "inserts = []\n",
        "count = 0"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI_u-2DEm_ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Method-3 \n",
        "with open(\"./people-raw.json\") as dataset: \n",
        "    for line in dataset: \n",
        "        inserts.append(InsertOne(loads(line)))\n",
        "        \n",
        "        count += 1\n",
        "                       \n",
        "        if count == batch_size:\n",
        "            people_raw.bulk_write(inserts)\n",
        "            inserts = []\n",
        "            count = 0\n",
        "if inserts:         \n",
        "    people_raw.bulk_write(inserts)\n",
        "    count = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1-2hU67m_ag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd29fd7c-cc7f-42a0-db02-9a1b027fa977"
      },
      "source": [
        "# Confirm that 50,474 documents are in your collection before moving on\n",
        "people_raw.count_documents({})"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50474"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sOFnx7Pm_aj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replace YYYY with a query on the people-raw collection that will return a cursor with only\n",
        "# documents where the birthday field is a string\n",
        "people_with_string_birthdays = people_raw.find({'birthday':{'$type':'string'}})\n",
        "filter={'birthday':{'$type':'string'}}"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIIToe1jm_am",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "62db0d66-b3ad-4248-ccbc-fd12e78eee20"
      },
      "source": [
        "# # This is the answer to verify you completed the lab\n",
        "people_raw.count_documents(filter)\n",
        "people_with_string_birthdays.count()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1382"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwT1ciG0m_ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "updates = []\n",
        "# Again, we're updating several thousand documents, so this will take a little while\n",
        "for person in people_with_string_birthdays:\n",
        "    # Pymongo converts datetime objects into BSON Dates. The dateparser.parse function returns a\n",
        "    # datetime object, so we can simply do the following to update the field properly.\n",
        "    # Replace ZZZZ with the correct update operator\n",
        "    updates.append(UpdateOne({ \"_id\": person[\"_id\"] }, { '$set': { \"birthday\": dateparser.parse(person[\"birthday\"]) } }))\n",
        "    \n",
        "    count += 1\n",
        "                       \n",
        "    if count == batch_size:\n",
        "        people_raw.bulk_write(updates)\n",
        "        updates = []\n",
        "        count = 0\n",
        "        \n",
        "if updates:         \n",
        "    people_raw.bulk_write(updates)\n",
        "    count = 0"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXVkhJR_m_ar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c9c86f74-f802-47ea-a108-fa5f502513b9"
      },
      "source": [
        "# If everything went well this should be zero\n",
        "people_with_string_birthdays.count()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    }
  ]
}